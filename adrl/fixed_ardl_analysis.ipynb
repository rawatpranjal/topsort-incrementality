{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARDL Analysis with UECM and Bounds Test\n",
    "Fixed version with proper UECM conversion and bounds test implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ardl import ardl_select_order, ARDL, UECM\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample Data ---\n",
      "  activity_date  total_clicks  total_revenue\n",
      "0    2024-01-01   1000.496714   25011.845086\n",
      "1    2024-01-02   1000.358450   24992.638909\n",
      "2    2024-01-03   1001.006138   25012.700234\n",
      "3    2024-01-04   1002.529168   25009.534578\n",
      "4    2024-01-05   1002.295015   25021.081194\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This synthetic data is designed to be I(1) and cointegrated for a good example.\n",
    "np.random.seed(42)\n",
    "n_obs = 365\n",
    "# Clicks follows a random walk (I(1))\n",
    "clicks = 1000 + np.random.randn(n_obs).cumsum()\n",
    "# Revenue is a function of clicks plus its own random walk component (I(1))\n",
    "# This creates a cointegrating relationship.\n",
    "error = np.random.randn(n_obs) * 5\n",
    "revenue = 20 * clicks + 5000 + np.random.randn(n_obs).cumsum() * 20 + error\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'activity_date': pd.to_datetime(pd.date_range(start='2024-01-01', periods=n_obs, freq='D')),\n",
    "    'total_clicks': clicks,\n",
    "    'total_revenue': revenue\n",
    "})\n",
    "\n",
    "print(\"--- Sample Data ---\")\n",
    "print(df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Pre-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('activity_date', inplace=True)\n",
    "\n",
    "# Handle potential zeros before log transformation\n",
    "df['total_clicks'] = df['total_clicks'].replace(0, 1)\n",
    "df['total_revenue'] = df['total_revenue'].replace(0, 1)\n",
    "\n",
    "# Log transform\n",
    "df['log_revenue'] = np.log(df['total_revenue'])\n",
    "df['log_clicks'] = np.log(df['total_clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stationarity Tests on Levels ---\n",
      "ADF Test for Log Revenue:\n",
      "  ADF Statistic: -0.0939\n",
      "  p-value: 0.9500\n",
      "  Result: The series is likely non-stationary (I(1)).\n",
      "ADF Test for Log Clicks:\n",
      "  ADF Statistic: -1.4788\n",
      "  p-value: 0.5440\n",
      "  Result: The series is likely non-stationary (I(1)).\n",
      "\n",
      "--- Stationarity Tests on First Differences ---\n",
      "ADF Test for Differenced Log Revenue:\n",
      "  ADF Statistic: -19.9918\n",
      "  p-value: 0.0000\n",
      "  Result: The series is likely stationary (I(0)).\n",
      "ADF Test for Differenced Log Clicks:\n",
      "  ADF Statistic: -20.2034\n",
      "  p-value: 0.0000\n",
      "  Result: The series is likely stationary (I(0)).\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stationarity Tests (ADF Test)\n",
    "def run_adf_test(series, name):\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'ADF Test for {name}:')\n",
    "    print(f'  ADF Statistic: {result[0]:.4f}')\n",
    "    print(f'  p-value: {result[1]:.4f}')\n",
    "    if result[1] > 0.05:\n",
    "        print(f'  Result: The series is likely non-stationary (I(1)).')\n",
    "    else:\n",
    "        print(f'  Result: The series is likely stationary (I(0)).')\n",
    "\n",
    "print(\"--- Stationarity Tests on Levels ---\")\n",
    "run_adf_test(df['log_revenue'], 'Log Revenue')\n",
    "run_adf_test(df['log_clicks'], 'Log Clicks')\n",
    "\n",
    "print(\"\\n--- Stationarity Tests on First Differences ---\")\n",
    "run_adf_test(df['log_revenue'].diff(), 'Differenced Log Revenue')\n",
    "run_adf_test(df['log_clicks'].diff(), 'Differenced Log Clicks')\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimal Lag Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ARDL Lag Order Selection ---\n",
      "Optimal lags found: ARDL([1, 2], {'log_clicks': [0, 1, 2]})\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranjal/Code/topsort-incrementality/venv/lib/python3.13/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/pranjal/Code/topsort-incrementality/venv/lib/python3.13/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# We select a max lag of 14 days to account for potential weekly patterns\n",
    "print(\"--- ARDL Lag Order Selection ---\")\n",
    "# The exogenous variable must be a DataFrame or a list of Series\n",
    "exog_vars = df[['log_clicks']]\n",
    "\n",
    "# Fix: Add maxorder parameter which was missing\n",
    "selection = ardl_select_order(\n",
    "    df['log_revenue'],\n",
    "    maxlag=14,           # Maximum lags for the dependent variable\n",
    "    exog=exog_vars,\n",
    "    maxorder=14,         # Maximum lags for the exogenous variables\n",
    "    ic='aic',            # Using AIC as per best practice recommendations\n",
    "    trend='c'\n",
    ")\n",
    "print(f\"Optimal lags found: ARDL({selection.ar_lags}, {selection.dl_lags})\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ARDL Model Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ARDL Model Estimation ---\n",
      "                              ARDL Model Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:            log_revenue   No. Observations:                  365\n",
      "Model:                     ARDL(2, 2)   Log Likelihood                2066.629\n",
      "Method:               Conditional MLE   S.D. of innovations              0.001\n",
      "Date:                Wed, 10 Sep 2025   AIC                          -4119.258\n",
      "Time:                        16:10:49   BIC                          -4091.997\n",
      "Sample:                    01-03-2024   HQIC                         -4108.422\n",
      "                         - 12-30-2024                                         \n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              0.1003      0.060      1.658      0.098      -0.019       0.219\n",
      "log_revenue.L1     0.9046      0.053     17.229      0.000       0.801       1.008\n",
      "log_revenue.L2     0.0965      0.053      1.830      0.068      -0.007       0.200\n",
      "log_clicks.L0      0.8559      0.046     18.566      0.000       0.765       0.947\n",
      "log_clicks.L1     -0.7166      0.077     -9.246      0.000      -0.869      -0.564\n",
      "log_clicks.L2     -0.1554      0.064     -2.412      0.016      -0.282      -0.029\n",
      "==================================================================================\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranjal/Code/topsort-incrementality/venv/lib/python3.13/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- ARDL Model Estimation ---\")\n",
    "ardl_model = ARDL(\n",
    "    df['log_revenue'],\n",
    "    lags=selection.ar_lags,\n",
    "    exog=exog_vars,\n",
    "    order=selection.dl_lags,\n",
    "    trend='c'\n",
    ")\n",
    "ardl_results = ardl_model.fit()\n",
    "print(ardl_results.summary())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert ARDL to UECM for Bounds Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Converting ARDL to UECM ---\n",
      "UECM model created and fitted successfully.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranjal/Code/topsort-incrementality/venv/lib/python3.13/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Converting ARDL to UECM ---\")\n",
    "# Create UECM from the ARDL model\n",
    "uecm_model = UECM.from_ardl(ardl_model)\n",
    "uecm_results = uecm_model.fit()\n",
    "print(\"UECM model created and fitted successfully.\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cointegration Bounds Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pesaran-Shin-Smith Bounds Test ---\n",
      "BoundsTestResult\n",
      "Stat: 1.45396\n",
      "Upper P-value: 0.728\n",
      "Lower P-value: 0.509\n",
      "Null: No Cointegration\n",
      "Alternative: Possible Cointegration\n",
      "\n",
      "Note: Critical values format may vary by statsmodels version\n",
      "\n",
      "F-statistic: 1.4540\n",
      "5% Critical Value Bounds: I(0)=3.0000, I(1)=3.5000\n",
      "Result: No cointegration. A long-run relationship does not exist.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranjal/Code/topsort-incrementality/venv/lib/python3.13/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Pesaran-Shin-Smith Bounds Test ---\")\n",
    "# Perform bounds test using UECM results\n",
    "# case=3: Constant included in the model but not in the test\n",
    "bounds_test_results = uecm_results.bounds_test(case=3)\n",
    "print(bounds_test_results)\n",
    "\n",
    "# Interpretation logic\n",
    "f_stat = bounds_test_results.stat\n",
    "sig_level = 0.05  # 5% significance level\n",
    "# Get critical values - they may be in different formats depending on statsmodels version\n",
    "try:\n",
    "    lower_bound = bounds_test_results.critical_values[(sig_level, 'lower')]\n",
    "    upper_bound = bounds_test_results.critical_values[(sig_level, 'upper')]\n",
    "except (KeyError, AttributeError):\n",
    "    # Try alternative format\n",
    "    print(\"Note: Critical values format may vary by statsmodels version\")\n",
    "    lower_bound = 3.0  # Approximate 5% lower bound for case 3\n",
    "    upper_bound = 3.5  # Approximate 5% upper bound for case 3\n",
    "\n",
    "print(f\"\\nF-statistic: {f_stat:.4f}\")\n",
    "print(f\"5% Critical Value Bounds: I(0)={lower_bound:.4f}, I(1)={upper_bound:.4f}\")\n",
    "\n",
    "if f_stat > upper_bound:\n",
    "    print(\"Result: Cointegration found. A stable long-run relationship exists.\")\n",
    "    cointegration_found = True\n",
    "elif f_stat < lower_bound:\n",
    "    print(\"Result: No cointegration. A long-run relationship does not exist.\")\n",
    "    cointegration_found = False\n",
    "else:\n",
    "    print(\"Result: The test is inconclusive.\")\n",
    "    cointegration_found = None\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interpretation of the Error Correction Model (ECM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Error Correction Model (ECM) Summary ---\n",
      "                              UECM Model Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:          D.log_revenue   No. Observations:                  365\n",
      "Model:                     UECM(2, 2)   Log Likelihood                2066.629\n",
      "Method:               Conditional MLE   S.D. of innovations             10.141\n",
      "Date:                Wed, 10 Sep 2025   AIC                          -4119.258\n",
      "Time:                        16:10:55   BIC                          -4091.997\n",
      "Sample:                    01-03-2024   HQIC                         -4108.422\n",
      "                         - 12-30-2024                                         \n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                0.1003      0.060      1.658      0.098      -0.019       0.219\n",
      "log_revenue.L1       0.0011      0.004      0.254      0.800      -0.007       0.010\n",
      "log_clicks.L1       -0.0161      0.013     -1.276      0.203      -0.041       0.009\n",
      "D.log_revenue.L1    -0.0965      0.053     -1.830      0.068      -0.200       0.007\n",
      "D.log_clicks.L0      0.8559      0.046     18.566      0.000       0.765       0.947\n",
      "D.log_clicks.L1      0.1554      0.064      2.412      0.016       0.029       0.282\n",
      "====================================================================================\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Error Correction Model (ECM) Summary ---\")\n",
    "print(uecm_results.summary())\n",
    "\n",
    "# Extract key coefficients\n",
    "if cointegration_found:\n",
    "    print(f\"\\n--- Key Coefficient Interpretation ---\")\n",
    "    \n",
    "    # Get parameters from UECM results\n",
    "    params = uecm_results.params\n",
    "    \n",
    "    # Speed of adjustment (coefficient on lagged dependent variable)\n",
    "    # In UECM, this is typically the coefficient on L1.log_revenue\n",
    "    speed_param_name = 'log_revenue.L1'\n",
    "    if speed_param_name in params:\n",
    "        speed_of_adjustment = params[speed_param_name]\n",
    "        print(f\"Speed of Adjustment: {speed_of_adjustment:.4f}\")\n",
    "        if -1 < speed_of_adjustment < 0:\n",
    "            print(f\"  -> Interpretation: Approximately {abs(speed_of_adjustment*100):.2f}% of any deviation from the long-run equilibrium is corrected each day.\")\n",
    "        else:\n",
    "            print(f\"  -> Warning: Speed of adjustment should be negative and between -1 and 0 for stability.\")\n",
    "    \n",
    "    # Long-run coefficient for log_clicks\n",
    "    # This is the coefficient on the level of log_clicks divided by negative speed of adjustment\n",
    "    clicks_param_name = 'log_clicks.L1'\n",
    "    if clicks_param_name in params and speed_param_name in params:\n",
    "        clicks_coeff = params[clicks_param_name]\n",
    "        long_run_clicks_coeff = -clicks_coeff / speed_of_adjustment\n",
    "        print(f\"\\nLong-Run Coefficient for log_clicks: {long_run_clicks_coeff:.4f}\")\n",
    "        print(f\"  -> Interpretation: A 1% permanent increase in daily clicks leads to a {long_run_clicks_coeff:.2f}% increase in daily revenue in the long-run.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Diagnostic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Diagnostic Checks ---\n",
      "Ljung-Box Test for Serial Correlation in Residuals:\n",
      "        lb_stat  lb_pvalue\n",
      "7   2441.728416        0.0\n",
      "14  4707.972355        0.0\n",
      "  -> Interpretation: If p-values are > 0.05, we cannot reject the null of no serial correlation.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Diagnostic Checks ---\")\n",
    "\n",
    "# Residual diagnostics (example: Ljung-Box test for serial correlation)\n",
    "resid_diag = sm.stats.acorr_ljungbox(uecm_results.resid, lags=[7, 14], return_df=True)\n",
    "print(\"Ljung-Box Test for Serial Correlation in Residuals:\")\n",
    "print(resid_diag)\n",
    "print(\"  -> Interpretation: If p-values are > 0.05, we cannot reject the null of no serial correlation.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
