{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "886abbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.connection:Snowflake Connector for Python Version: 3.17.3, Python Version: 3.13.7, Platform: macOS-14.5-arm64-arm-64bit-Mach-O\n",
      "INFO:snowflake.connector.connection:Connecting to GLOBAL Snowflake domain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating 2-month panel for TOP 80% of Power Players ---\n",
      "    - Identifying performers from: 2025-05-01 to 2025-06-01\n",
      "    - Building panel for period:   2025-06-01 to 2025-08-01\n",
      "✅ Connected to Snowflake\n",
      "Executing query...\n",
      "✅ Query successful. Fetched 1,466,907 rows.\n",
      "✅ Data successfully processed and saved to 'user_vendor_panel_power_players_2mo.parquet'\n",
      "✅ Snowflake connection closed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "def connect_to_snowflake():\n",
    "    \"\"\"Establishes a connection to Snowflake using environment variables.\"\"\"\n",
    "    # ... (this function is unchanged) ...\n",
    "    try:\n",
    "        conn = snowflake.connector.connect(\n",
    "            user=os.getenv('SNOWFLAKE_USER'),\n",
    "            password=os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "            account=os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "            warehouse=os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH'),\n",
    "            database='INCREMENTALITY',\n",
    "            schema='INCREMENTALITY_RESEARCH'\n",
    "        )\n",
    "        print(\"✅ Connected to Snowflake\")\n",
    "        return conn\n",
    "    except snowflake.connector.Error as e:\n",
    "        print(f\"❌ Could not connect to Snowflake: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "def build_power_player_panel_query(prior_period_start, prior_period_end, analysis_period_start, analysis_period_end, threshold=0.80):\n",
    "    \"\"\"\n",
    "    Builds a SQL query to create a panel for an analysis period, filtered by a\n",
    "    two-stage process: first top vendors, then top users on those vendors.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    WITH\n",
    "    -- Step 1: Create a universal Product -> Vendor map for attribution\n",
    "    PRODUCT_VENDOR_MAP AS (\n",
    "        SELECT DISTINCT PRODUCT_ID, VENDOR_ID\n",
    "        FROM CLICKS\n",
    "        WHERE PRODUCT_ID IS NOT NULL AND VENDOR_ID IS NOT NULL\n",
    "    ),\n",
    "\n",
    "    -- Step 2: Calculate all revenue in the PRIOR period (May) to find top vendors\n",
    "    MAY_REVENUE AS (\n",
    "        SELECT\n",
    "            p.USER_ID,\n",
    "            pvm.VENDOR_ID,\n",
    "            COALESCE(SUM(p.QUANTITY * p.UNIT_PRICE), 0) AS revenue_cents\n",
    "        FROM PURCHASES AS p\n",
    "        JOIN PRODUCT_VENDOR_MAP AS pvm ON p.PRODUCT_ID = pvm.PRODUCT_ID\n",
    "        WHERE p.PURCHASED_AT >= '{prior_period_start}' AND p.PURCHASED_AT < '{prior_period_end}'\n",
    "        GROUP BY 1, 2\n",
    "    ),\n",
    "\n",
    "    -- Step 3: Identify TOP VENDORS from May who make up the top 80% of revenue\n",
    "    TOP_VENDORS AS (\n",
    "        SELECT VENDOR_ID\n",
    "        FROM (\n",
    "            SELECT\n",
    "                VENDOR_ID,\n",
    "                SUM(revenue_cents) AS total_vendor_revenue,\n",
    "                SUM(total_vendor_revenue) OVER (ORDER BY total_vendor_revenue DESC) / SUM(total_vendor_revenue) OVER () AS cumulative_share\n",
    "            FROM MAY_REVENUE\n",
    "            GROUP BY VENDOR_ID\n",
    "        )\n",
    "        WHERE cumulative_share <= {threshold}\n",
    "    ),\n",
    "\n",
    "    -- Step 4: Now, find TOP USERS who spent the most AT THE TOP VENDORS in May\n",
    "    TOP_USERS AS (\n",
    "        SELECT USER_ID\n",
    "        FROM (\n",
    "            SELECT\n",
    "                USER_ID,\n",
    "                SUM(revenue_cents) AS total_user_revenue_at_top_vendors,\n",
    "                SUM(total_user_revenue_at_top_vendors) OVER (ORDER BY total_user_revenue_at_top_vendors DESC) / SUM(total_user_revenue_at_top_vendors) OVER () AS cumulative_share\n",
    "            FROM MAY_REVENUE\n",
    "            WHERE VENDOR_ID IN (SELECT VENDOR_ID FROM TOP_VENDORS) -- Filter for spend at top vendors\n",
    "            GROUP BY USER_ID\n",
    "        )\n",
    "        WHERE cumulative_share <= {threshold}\n",
    "    ),\n",
    "\n",
    "    -- Step 5: Aggregate clicks in the ANALYSIS period (June-July) for this \"power player\" population\n",
    "    CLICKS_U_V_W AS (\n",
    "        SELECT\n",
    "            USER_ID,\n",
    "            VENDOR_ID,\n",
    "            DATE_TRUNC('WEEK', OCCURRED_AT) AS week,\n",
    "            COUNT(DISTINCT INTERACTION_ID) AS click_count\n",
    "        FROM CLICKS\n",
    "        WHERE\n",
    "            OCCURRED_AT >= '{analysis_period_start}' AND OCCURRED_AT < '{analysis_period_end}'\n",
    "            AND USER_ID IN (SELECT USER_ID FROM TOP_USERS)\n",
    "            AND VENDOR_ID IN (SELECT VENDOR_ID FROM TOP_VENDORS)\n",
    "        GROUP BY 1, 2, 3\n",
    "    ),\n",
    "\n",
    "    -- Step 6: Aggregate purchases in the ANALYSIS period for the \"power player\" population\n",
    "    PURCHASES_U_V_W AS (\n",
    "        SELECT\n",
    "            p.USER_ID,\n",
    "            pvm.VENDOR_ID,\n",
    "            DATE_TRUNC('WEEK', p.PURCHASED_AT) AS week,\n",
    "            COUNT(DISTINCT p.PURCHASE_ID) AS purchase_count,\n",
    "            COALESCE(SUM(p.QUANTITY * p.UNIT_PRICE), 0) AS total_revenue_cents\n",
    "        FROM PURCHASES AS p\n",
    "        JOIN PRODUCT_VENDOR_MAP AS pvm ON p.PRODUCT_ID = pvm.PRODUCT_ID\n",
    "        WHERE\n",
    "            p.PURCHASED_AT >= '{analysis_period_start}' AND p.PURCHASED_AT < '{analysis_period_end}'\n",
    "            AND p.USER_ID IN (SELECT USER_ID FROM TOP_USERS)\n",
    "            AND pvm.VENDOR_ID IN (SELECT VENDOR_ID FROM TOP_VENDORS)\n",
    "        GROUP BY 1, 2, 3\n",
    "    )\n",
    "\n",
    "    -- Final Step: Join the analysis period data into the final panel\n",
    "    SELECT\n",
    "        COALESCE(c.week, p.week) AS week,\n",
    "        COALESCE(c.user_id, p.user_id) AS user_id,\n",
    "        COALESCE(c.vendor_id, p.vendor_id) AS vendor_id,\n",
    "        COALESCE(c.click_count, 0) AS clicks,\n",
    "        COALESCE(p.purchase_count, 0) AS purchases,\n",
    "        (COALESCE(p.total_revenue_cents, 0) / 100)::DECIMAL(18, 2) AS revenue_dollars\n",
    "        \n",
    "    FROM CLICKS_U_V_W AS c\n",
    "    FULL OUTER JOIN PURCHASES_U_V_W AS p\n",
    "        ON c.user_id = p.user_id AND c.vendor_id = p.vendor_id AND c.week = p.week\n",
    "    ORDER BY\n",
    "        user_id, vendor_id, week;\n",
    "    \"\"\"\n",
    "    return query\n",
    "\n",
    "def fetch_panel_data(conn, query):\n",
    "    # ... (this function is unchanged) ...\n",
    "    print(\"Executing query...\")\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        if cursor.description:\n",
    "            results = cursor.fetchall()\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            df = pd.DataFrame(results, columns=columns)\n",
    "            print(f\"✅ Query successful. Fetched {len(df):,} rows.\")\n",
    "            return df\n",
    "        return pd.DataFrame()\n",
    "    except snowflake.connector.Error as e:\n",
    "        print(f\"\\n❌ ERROR executing query: {e}\", file=sys.stderr)\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "def process_and_save_data(df, filename):\n",
    "    # ... (this function is unchanged) ...\n",
    "    if df.empty:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "    try:\n",
    "        df.columns = [col.lower() for col in df.columns]\n",
    "        df.to_parquet(filename, index=False, engine='pyarrow')\n",
    "        print(f\"✅ Data successfully processed and saved to '{filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to save data to '{filename}': {e}\", file=sys.stderr)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the data extraction and saving process.\n",
    "    \"\"\"\n",
    "    # --- CONFIGURATION ---\n",
    "    # Define the monthly periods for the analysis\n",
    "    PRIOR_PERIOD_START = '2025-05-01'\n",
    "    PRIOR_PERIOD_END = '2025-06-01'\n",
    "    ANALYSIS_PERIOD_START = '2025-06-01'\n",
    "    ANALYSIS_PERIOD_END = '2025-08-01' # 2 months: June and July\n",
    "    \n",
    "    CUMULATIVE_SHARE_THRESHOLD = 0.80\n",
    "    \n",
    "    OUTPUT_FILENAME = \"user_vendor_panel_power_players_2mo.parquet\"\n",
    "    # ---------------------\n",
    "\n",
    "    print(f\"--- Generating 2-month panel for TOP {CUMULATIVE_SHARE_THRESHOLD:.0%} of Power Players ---\")\n",
    "    print(f\"    - Identifying performers from: {PRIOR_PERIOD_START} to {PRIOR_PERIOD_END}\")\n",
    "    print(f\"    - Building panel for period:   {ANALYSIS_PERIOD_START} to {ANALYSIS_PERIOD_END}\")\n",
    "\n",
    "    conn = connect_to_snowflake()\n",
    "    if not conn:\n",
    "        sys.exit(1)\n",
    "\n",
    "    try:\n",
    "        query = build_power_player_panel_query(\n",
    "            prior_period_start=PRIOR_PERIOD_START,\n",
    "            prior_period_end=PRIOR_PERIOD_END,\n",
    "            analysis_period_start=ANALYSIS_PERIOD_START,\n",
    "            analysis_period_end=ANALYSIS_PERIOD_END,\n",
    "            threshold=CUMULATIVE_SHARE_THRESHOLD\n",
    "        )\n",
    "        \n",
    "        panel_df = fetch_panel_data(conn, query)\n",
    "        \n",
    "        process_and_save_data(panel_df, OUTPUT_FILENAME)\n",
    "\n",
    "    finally:\n",
    "        if conn and not conn.is_closed():\n",
    "            print(\"✅ Snowflake connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "624ce125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading data from 'user_vendor_panel_power_players_2mo.parquet' ---\n",
      "✅ Data loaded successfully with 1,466,907 rows.\n",
      "\n",
      "--- EDA 1: High-Level Overview & Panel Structure ---\n",
      "Assessing the dimensions and balance of the 2-month power player panel.\n",
      "\n",
      "Dataset Dimensions (June-July)\n",
      "==============================\n",
      "+----------------------------------------+---------+\n",
      "| Metric                                 |   Value |\n",
      "+========================================+=========+\n",
      "| Total Observations (User-Vendor-Weeks) | 1466907 |\n",
      "+----------------------------------------+---------+\n",
      "| Unique Power Users                     |   58306 |\n",
      "+----------------------------------------+---------+\n",
      "| Unique Power Vendors                   |   11220 |\n",
      "+----------------------------------------+---------+\n",
      "| Unique Weeks in Panel                  |      10 |\n",
      "+----------------------------------------+---------+\n",
      "\n",
      "Distribution of Observations per User\n",
      "=====================================\n",
      "+-------------+----------------+\n",
      "| statistic   |   obs_per_user |\n",
      "+=============+================+\n",
      "| count       |     58306      |\n",
      "+-------------+----------------+\n",
      "| null_count  |         0      |\n",
      "+-------------+----------------+\n",
      "| mean        |        25.1588 |\n",
      "+-------------+----------------+\n",
      "| std         |        52.0546 |\n",
      "+-------------+----------------+\n",
      "| min         |         1      |\n",
      "+-------------+----------------+\n",
      "| 25%         |         3      |\n",
      "+-------------+----------------+\n",
      "| 50%         |         9      |\n",
      "+-------------+----------------+\n",
      "| 75%         |        26      |\n",
      "+-------------+----------------+\n",
      "| max         |      3967      |\n",
      "+-------------+----------------+\n",
      "\n",
      "Distribution of Observations per Vendor\n",
      "=======================================\n",
      "+-------------+------------------+\n",
      "| statistic   |   obs_per_vendor |\n",
      "+=============+==================+\n",
      "| count       |        11220     |\n",
      "+-------------+------------------+\n",
      "| null_count  |            0     |\n",
      "+-------------+------------------+\n",
      "| mean        |          130.74  |\n",
      "+-------------+------------------+\n",
      "| std         |          164.069 |\n",
      "+-------------+------------------+\n",
      "| min         |            1     |\n",
      "+-------------+------------------+\n",
      "| 25%         |           41     |\n",
      "+-------------+------------------+\n",
      "| 50%         |           86     |\n",
      "+-------------+------------------+\n",
      "| 75%         |          158     |\n",
      "+-------------+------------------+\n",
      "| max         |         2884     |\n",
      "+-------------+------------------+\n",
      "\n",
      "Interpretation: These tables show how active power users and vendors are over the 2-month period.\n",
      "\n",
      "--- EDA 2: Weekly Platform Trends (June-July) ---\n",
      "This shows the evolution of the power player ecosystem over time.\n",
      "\n",
      "Week-over-Week Platform Metrics\n",
      "===============================\n",
      "+---------------------+-----------------+----------------+----------------+------------------+\n",
      "| week                |   total_revenue |   total_clicks |   active_users |   active_vendors |\n",
      "+=====================+=================+================+================+==================+\n",
      "| 2025-05-26 00:00:00 |          102182 |          45408 |          12892 |             7976 |\n",
      "+---------------------+-----------------+----------------+----------------+------------------+\n",
      "| 2025-06-02 00:00:00 |          645262 |         247371 |          33467 |             9854 |\n",
      "+---------------------+-----------------+----------------+----------------+------------------+\n",
      "| 2025-06-09 00:00:00 |          537734 |         219277 |          30973 |             9493 |\n",
      "+---------------------+-----------------+----------------+----------------+------------------+\n",
      "| 2025-06-16 00:00:00 |          570969 |         212036 |          30146 |             9227 |\n",
      "+---------------------+-----------------+----------------+----------------+------------------+\n",
      "| 2025-06-23 00:00:00 |          518502 |         202501 |          29219 |             8985 |\n",
      "+---------------------+-----------------+----------------+----------------+------------------+\n",
      "| 2025-06-30 00:00:00 |          450036 |         198127 |          28200 |             8809 |\n",
      "+---------------------+-----------------+----------------+----------------+------------------+\n",
      "| 2025-07-07 00:00:00 |          446414 |         188298 |          27683 |             8703 |\n",
      "+---------------------+-----------------+----------------+----------------+------------------+\n",
      "| 2025-07-14 00:00:00 |          431572 |         188266 |          27561 |             8569 |\n",
      "+---------------------+-----------------+----------------+----------------+------------------+\n",
      "| 2025-07-21 00:00:00 |          386590 |         183380 |          26999 |             8335 |\n",
      "+---------------------+-----------------+----------------+----------------+------------------+\n",
      "| 2025-07-28 00:00:00 |          200756 |         100580 |          20000 |             7758 |\n",
      "+---------------------+-----------------+----------------+----------------+------------------+\n",
      "\n",
      "Interpretation: Look for trends, seasonality, or shocks in activity within the power player segment.\n",
      "\n",
      "--- EDA 3: The Nature of Conversion & 'Treatment' (Clicks) ---\n",
      "\n",
      "'Zero-Click' Conversions: 72.65% of purchasing events had zero same-week clicks.\n",
      "Interpretation: A high percentage confirms that purchase journeys are longer than a single week, even in this long panel.\n",
      "\n",
      "Distribution for Purchasing Interactions ONLY\n",
      "=============================================\n",
      "+-------------+-------------+--------------+-------------------+\n",
      "| statistic   |      clicks |    purchases |   revenue_dollars |\n",
      "+=============+=============+==============+===================+\n",
      "| count       | 66578       | 66578        |        66578      |\n",
      "+-------------+-------------+--------------+-------------------+\n",
      "| null_count  |     0       |     0        |            0      |\n",
      "+-------------+-------------+--------------+-------------------+\n",
      "| mean        |     0.50718 |     1.07932  |           64.4359 |\n",
      "+-------------+-------------+--------------+-------------------+\n",
      "| std         |     1.15628 |     0.362157 |          151.266  |\n",
      "+-------------+-------------+--------------+-------------------+\n",
      "| min         |     0       |     1        |            3      |\n",
      "+-------------+-------------+--------------+-------------------+\n",
      "| 25%         |     0       |     1        |           18      |\n",
      "+-------------+-------------+--------------+-------------------+\n",
      "| 50%         |     0       |     1        |           30      |\n",
      "+-------------+-------------+--------------+-------------------+\n",
      "| 75%         |     1       |     1        |           61      |\n",
      "+-------------+-------------+--------------+-------------------+\n",
      "| max         |    33       |    15        |         9120      |\n",
      "+-------------+-------------+--------------+-------------------+\n",
      "\n",
      "--- EDA 4: Player Persistence & Stickiness ---\n",
      "How consistently are power players active from week to week?\n",
      "\n",
      "User Weekly Activity Distribution\n",
      "=================================\n",
      "+----------------+---------+\n",
      "|   weeks_active |   count |\n",
      "+================+=========+\n",
      "|             10 |    3659 |\n",
      "+----------------+---------+\n",
      "|              9 |    4651 |\n",
      "+----------------+---------+\n",
      "|              8 |    4366 |\n",
      "+----------------+---------+\n",
      "|              7 |    4455 |\n",
      "+----------------+---------+\n",
      "|              6 |    4640 |\n",
      "+----------------+---------+\n",
      "|              5 |    4950 |\n",
      "+----------------+---------+\n",
      "|              4 |    5675 |\n",
      "+----------------+---------+\n",
      "|              3 |    6520 |\n",
      "+----------------+---------+\n",
      "|              2 |    8338 |\n",
      "+----------------+---------+\n",
      "|              1 |   11052 |\n",
      "+----------------+---------+\n",
      "\n",
      "Vendor Weekly Activity Distribution\n",
      "===================================\n",
      "+----------------+---------+\n",
      "|   weeks_active |   count |\n",
      "+================+=========+\n",
      "|             10 |    5145 |\n",
      "+----------------+---------+\n",
      "|              9 |    1768 |\n",
      "+----------------+---------+\n",
      "|              8 |     777 |\n",
      "+----------------+---------+\n",
      "|              7 |     607 |\n",
      "+----------------+---------+\n",
      "|              6 |     485 |\n",
      "+----------------+---------+\n",
      "|              5 |     443 |\n",
      "+----------------+---------+\n",
      "|              4 |     450 |\n",
      "+----------------+---------+\n",
      "|              3 |     440 |\n",
      "+----------------+---------+\n",
      "|              2 |     532 |\n",
      "+----------------+---------+\n",
      "|              1 |     573 |\n",
      "+----------------+---------+\n",
      "\n",
      "Interpretation: This shows loyalty and churn. A high number of users active for only 1-2 weeks indicates high churn, even among power users.\n",
      "\n",
      "--- EDA 5: Top Performer Analysis (June-July) ---\n",
      "\n",
      "Top 15 Vendors by Revenue (June-July)\n",
      "=====================================\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| vendor_id                            | total_revenue_2mo   |   total_clicks_2mo |   unique_users_reached_2mo |\n",
      "+======================================+=====================+====================+============================+\n",
      "| 018e9acf-caf5-7295-a2f1-77838c5bf461 | $114,423.00         |                540 |                        481 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 064ce6ab-dd22-7987-a124-0b003531c280 | $76,901.00          |                705 |                        763 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 0191395a-0b37-7320-a144-46ec5b6aaea7 | $51,750.00          |                245 |                        336 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 01961cdc-dfe1-76a0-b444-1c425612639a | $50,430.00          |                224 |                        258 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 065aa9de-b679-724a-9e24-512ec8e95549 | $49,224.00          |                566 |                        566 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 065298be-a5e6-7435-ad24-36ff8f3c7c7c | $49,093.00          |                450 |                        355 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 065cf9c7-ccc6-7f05-a424-af01485765d0 | $43,399.00          |                156 |                        217 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 018fcf85-289a-775d-af25-3a6ec4cc4a60 | $40,179.00          |                189 |                        197 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 06573724-0b58-7789-8b24-84cfe1d17e8f | $33,042.00          |                316 |                        309 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 0193dc88-8dbe-7a40-a3ad-893595e6f652 | $32,502.00          |                182 |                        176 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 06446aa9-e970-79d2-b524-0d11f0c5341e | $30,083.00          |                651 |                        536 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 064888ef-4203-7906-a424-9e4df1ac45fd | $27,720.00          |                610 |                        435 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 018e87e9-5869-76d0-8b3d-4cc4e9c99472 | $27,281.00          |                471 |                        272 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 064a066b-e9c1-7796-a924-4ca87109029f | $27,007.00          |               1122 |                        711 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "| 0196f100-d201-7233-9f2b-04f4b09f38c4 | $24,870.00          |                139 |                        180 |\n",
      "+--------------------------------------+---------------------+--------------------+----------------------------+\n",
      "\n",
      "Top 15 Users by Revenue (June-July)\n",
      "===================================\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| user_id                                   | total_revenue_2mo   |   total_clicks_2mo |   vendors_interacted_with_2mo |\n",
      "+===========================================+=====================+====================+===============================+\n",
      "| ext1:6253ed97-3b9e-4bc6-9934-00e41b6d53a5 | $21,910.00          |                 46 |                            49 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:f82e7a91-8d04-48eb-ab01-0ad94e817758 | $18,129.00          |                 55 |                            41 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:de237a90-d8bd-4bb7-a304-28761dbd36f6 | $15,711.00          |                  1 |                             3 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:b89119b5-362d-4150-9db5-374fc0b3539a | $11,259.00          |                  1 |                             8 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:7f09acc7-b73a-4a03-a3ee-b717b81d6ab8 | $10,807.00          |                 71 |                            61 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:d2f5fc72-a031-424d-b38f-dec63429e740 | $10,719.00          |                  7 |                            24 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:ee0be8a4-9748-4288-bca6-2fc7b1ea8df9 | $10,606.00          |                  3 |                            14 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:635532df-97ca-41b8-a5c5-cf5a822ce4f7 | $10,548.00          |                 11 |                            28 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:3bc1c358-38cf-48ee-8471-9162c90a34ce | $9,800.00           |                228 |                           183 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:859f2621-f1ab-4c34-b712-57eb733b6a6f | $9,567.00           |                 56 |                            50 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:0f91ffe2-4fb5-4582-9d3b-552315f8b997 | $9,327.00           |                 64 |                            57 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:8700224b-004b-4fe1-99ef-9c762e459824 | $9,174.00           |                  3 |                             4 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:0bc9a6ac-122c-403e-8d03-237346593e3f | $9,048.00           |                 86 |                            90 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:9886eebf-eee4-4240-8219-dc38631c623f | $8,706.00           |                  6 |                            19 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "| ext1:2f1af48b-2476-4b76-8995-a463d5f03b35 | $8,682.00           |                 16 |                            32 |\n",
      "+-------------------------------------------+---------------------+--------------------+-------------------------------+\n",
      "\n",
      "--- EDA 6: Market Concentration (June-July) ---\n",
      "\n",
      "Revenue Concentration\n",
      "=====================\n",
      "+-------------------+---------------------+\n",
      "| Group             |   Revenue Share (%) |\n",
      "+===================+=====================+\n",
      "| Top 1% of Vendors |             37.2477 |\n",
      "+-------------------+---------------------+\n",
      "| Top 5% of Vendors |             58.241  |\n",
      "+-------------------+---------------------+\n",
      "\n",
      "Interpretation: High concentration means the market is dominated by a few key players.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/1tvk5qmx0ds9c6gk2lrlhv380000gn/T/ipykernel_62543/196114025.py:39: DeprecationWarning: `DataFrame.melt` is deprecated; use `DataFrame.unpivot` instead, with `index` instead of `id_vars` and `on` instead of `value_vars`\n",
      "  ).melt().rename({\"variable\": \"Metric\", \"value\": \"Value\"})\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from tabulate import tabulate\n",
    "\n",
    "# --- Helper Function (to make this script runnable standalone) ---\n",
    "def show_table(df, title=\"\"):\n",
    "    \"\"\"Prints a Polars DataFrame in a formatted grid table by converting it to Pandas.\"\"\"\n",
    "    if title:\n",
    "        print(f\"\\n{title}\")\n",
    "        print(\"=\"*len(title))\n",
    "    print(tabulate(df.to_pandas(), headers='keys', tablefmt='grid', showindex=False))\n",
    "\n",
    "# --- Prerequisite: Load Data ---\n",
    "try:\n",
    "    # UPDATED FILENAME for the new power player data\n",
    "    parquet_filename = 'user_vendor_panel_power_players_2mo.parquet'\n",
    "    \n",
    "    print(f\"--- Loading data from '{parquet_filename}' ---\")\n",
    "    df_analysis = pl.read_parquet(parquet_filename).with_columns(\n",
    "        pl.col(\"revenue_dollars\").cast(pl.Float64)\n",
    "    )\n",
    "    print(f\"✅ Data loaded successfully with {df_analysis.height:,} rows.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ ERROR: The file '{parquet_filename}' was not found.\")\n",
    "    print(\"   Please run the new power player data generation script first.\")\n",
    "    df_analysis = None\n",
    "\n",
    "# --- Main EDA Block ---\n",
    "if df_analysis is not None and not df_analysis.is_empty():\n",
    "\n",
    "    # --- EDA 1: High-Level Overview & Panel Structure ---\n",
    "    print(\"\\n--- EDA 1: High-Level Overview & Panel Structure ---\")\n",
    "    print(\"Assessing the dimensions and balance of the 2-month power player panel.\")\n",
    "\n",
    "    summary_stats = df_analysis.select(\n",
    "        pl.len().alias(\"Total Observations (User-Vendor-Weeks)\"),\n",
    "        pl.col(\"user_id\").n_unique().alias(\"Unique Power Users\"),\n",
    "        pl.col(\"vendor_id\").n_unique().alias(\"Unique Power Vendors\"),\n",
    "        pl.col(\"week\").n_unique().alias(\"Unique Weeks in Panel\")\n",
    "    ).melt().rename({\"variable\": \"Metric\", \"value\": \"Value\"})\n",
    "    show_table(summary_stats, \"Dataset Dimensions (June-July)\")\n",
    "\n",
    "    # Observations per User\n",
    "    obs_per_user = df_analysis.group_by(\"user_id\").len().select(pl.col(\"len\").alias(\"obs_per_user\"))\n",
    "    show_table(obs_per_user.describe(), \"Distribution of Observations per User\")\n",
    "    \n",
    "    # Observations per Vendor\n",
    "    obs_per_vendor = df_analysis.group_by(\"vendor_id\").len().select(pl.col(\"len\").alias(\"obs_per_vendor\"))\n",
    "    show_table(obs_per_vendor.describe(), \"Distribution of Observations per Vendor\")\n",
    "    print(\"\\nInterpretation: These tables show how active power users and vendors are over the 2-month period.\")\n",
    "\n",
    "    # --- EDA 2: Weekly Platform Trends ---\n",
    "    print(\"\\n--- EDA 2: Weekly Platform Trends (June-July) ---\")\n",
    "    print(\"This shows the evolution of the power player ecosystem over time.\")\n",
    "    \n",
    "    weekly_trends = (\n",
    "        df_analysis.group_by(\"week\")\n",
    "        .agg(\n",
    "            pl.col(\"revenue_dollars\").sum().alias(\"total_revenue\"),\n",
    "            pl.col(\"clicks\").sum().alias(\"total_clicks\"),\n",
    "            pl.col(\"user_id\").n_unique().alias(\"active_users\"),\n",
    "            pl.col(\"vendor_id\").n_unique().alias(\"active_vendors\")\n",
    "        )\n",
    "        .sort(\"week\")\n",
    "    )\n",
    "    show_table(weekly_trends, \"Week-over-Week Platform Metrics\")\n",
    "    print(\"\\nInterpretation: Look for trends, seasonality, or shocks in activity within the power player segment.\")\n",
    "\n",
    "    # --- EDA 3: The Nature of Conversion & 'Treatment' (Clicks) ---\n",
    "    print(\"\\n--- EDA 3: The Nature of Conversion & 'Treatment' (Clicks) ---\")\n",
    "    \n",
    "    df_purchasing = df_analysis.filter(pl.col(\"purchases\") > 0)\n",
    "    \n",
    "    if df_purchasing.is_empty():\n",
    "        print(\"\\nWARNING: No purchasing interactions found in the dataset.\")\n",
    "    else:\n",
    "        zero_click_conversions_pct = df_purchasing.select(\n",
    "            (pl.col(\"clicks\") == 0).mean() * 100\n",
    "        ).item()\n",
    "        print(f\"\\n'Zero-Click' Conversions: {zero_click_conversions_pct:.2f}% of purchasing events had zero same-week clicks.\")\n",
    "        print(\"Interpretation: A high percentage confirms that purchase journeys are longer than a single week, even in this long panel.\")\n",
    "\n",
    "        show_table(df_purchasing.select(['clicks', 'purchases', 'revenue_dollars']).describe(), \"Distribution for Purchasing Interactions ONLY\")\n",
    "\n",
    "    # --- EDA 4: Player Persistence & Stickiness ---\n",
    "    print(\"\\n--- EDA 4: Player Persistence & Stickiness ---\")\n",
    "    print(\"How consistently are power players active from week to week?\")\n",
    "\n",
    "    # Count how many weeks each user/vendor was active\n",
    "    user_weeks_active = df_analysis.group_by(\"user_id\").agg(pl.col(\"week\").n_unique().alias(\"weeks_active\"))\n",
    "    vendor_weeks_active = df_analysis.group_by(\"vendor_id\").agg(pl.col(\"week\").n_unique().alias(\"weeks_active\"))\n",
    "    \n",
    "    # Show the distribution of active weeks\n",
    "    show_table(user_weeks_active.get_column(\"weeks_active\").value_counts().sort(\"weeks_active\", descending=True), \"User Weekly Activity Distribution\")\n",
    "    show_table(vendor_weeks_active.get_column(\"weeks_active\").value_counts().sort(\"weeks_active\", descending=True), \"Vendor Weekly Activity Distribution\")\n",
    "    print(\"\\nInterpretation: This shows loyalty and churn. A high number of users active for only 1-2 weeks indicates high churn, even among power users.\")\n",
    "    \n",
    "    # --- EDA 5: Top Performer Analysis (over the full 2 months) ---\n",
    "    print(\"\\n--- EDA 5: Top Performer Analysis (June-July) ---\")\n",
    "    \n",
    "    # Top Vendors over the full period\n",
    "    vendor_summary = (\n",
    "        df_analysis.group_by('vendor_id')\n",
    "        .agg(\n",
    "            pl.col('revenue_dollars').sum().alias('total_revenue_2mo'),\n",
    "            pl.col('clicks').sum().alias('total_clicks_2mo'),\n",
    "            pl.col('user_id').n_unique().alias('unique_users_reached_2mo')\n",
    "        )\n",
    "        .sort('total_revenue_2mo', descending=True)\n",
    "        .head(15)\n",
    "    )\n",
    "    vendor_summary = vendor_summary.with_columns(pl.col('total_revenue_2mo').map_elements(lambda x: f\"${x:,.2f}\"))\n",
    "    show_table(vendor_summary, \"Top 15 Vendors by Revenue (June-July)\")\n",
    "\n",
    "    # Top Users over the full period\n",
    "    user_summary = (\n",
    "        df_analysis.group_by('user_id')\n",
    "        .agg(\n",
    "            pl.col('revenue_dollars').sum().alias('total_revenue_2mo'),\n",
    "            pl.col('clicks').sum().alias('total_clicks_2mo'),\n",
    "            pl.col('vendor_id').n_unique().alias('vendors_interacted_with_2mo')\n",
    "        )\n",
    "        .sort('total_revenue_2mo', descending=True)\n",
    "        .head(15)\n",
    "    )\n",
    "    user_summary = user_summary.with_columns(pl.col('total_revenue_2mo').map_elements(lambda x: f\"${x:,.2f}\"))\n",
    "    show_table(user_summary, \"Top 15 Users by Revenue (June-July)\")\n",
    "    \n",
    "    # --- EDA 6: Market Concentration ---\n",
    "    print(\"\\n--- EDA 6: Market Concentration (June-July) ---\")\n",
    "    \n",
    "    vendor_revenue = df_analysis.group_by(\"vendor_id\").agg(pl.col(\"revenue_dollars\").sum().alias(\"total_revenue\"))\n",
    "    total_revenue_in_sample = vendor_revenue.get_column(\"total_revenue\").sum()\n",
    "    \n",
    "    if total_revenue_in_sample > 0:\n",
    "        n_vendors = len(vendor_revenue)\n",
    "        top_1_pct_vendors = vendor_revenue.sort(\"total_revenue\", descending=True).head(int(n_vendors * 0.01))\n",
    "        top_5_pct_vendors = vendor_revenue.sort(\"total_revenue\", descending=True).head(int(n_vendors * 0.05))\n",
    "        \n",
    "        rev_top_1 = top_1_pct_vendors.get_column(\"total_revenue\").sum()\n",
    "        rev_top_5 = top_5_pct_vendors.get_column(\"total_revenue\").sum()\n",
    "\n",
    "        concentration_summary = pl.DataFrame({\n",
    "            \"Group\": [\"Top 1% of Vendors\", \"Top 5% of Vendors\"],\n",
    "            \"Revenue Share (%)\": [\n",
    "                (rev_top_1 / total_revenue_in_sample) * 100,\n",
    "                (rev_top_5 / total_revenue_in_sample) * 100\n",
    "            ]\n",
    "        })\n",
    "        show_table(concentration_summary, \"Revenue Concentration\")\n",
    "        print(\"\\nInterpretation: High concentration means the market is dominated by a few key players.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nCould not perform EDA because the DataFrame is empty or could not be loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c76906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ rpy2 environment and 'fixest' library loaded successfully.\n",
      "--- Loading unbalanced panel data from 'user_vendor_panel_power_players_2mo.parquet' ---\n",
      "--- Sub-sampling 50% of users... ---\n",
      "✅ Sampled data contains 739,126 rows from 29,153 users.\n",
      "--- Balancing the panel for the sampled user-vendor pairs ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/1tvk5qmx0ds9c6gk2lrlhv380000gn/T/ipykernel_76473/2815795083.py:34: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  df_sampled = df_unbalanced.filter(pl.col(\"user_id\").is_in(sampled_users))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Panel balanced. New size: 6,706,230 rows.\n",
      "--- Preparing binary and lagged click variables ---\n",
      "✅ Lagged variables created successfully.\n",
      "\n",
      "--- Estimating Distributed Lag Panel Logit Model ---\n",
      "Model: Pr(Purchase=1) ~ Had_Click + Had_Click_Lag1 | FEs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R callback write-console: NOTES: 670,623 observations removed because of NA values (RHS: 670,623).\n",
      "       17,138/3,287/0 fixed-effects (2,572,740 observations) removed because of only 0 (or only 1) outcomes.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    model_dist_lag\n",
      "Dependent Var.:       did_purchase\n",
      "                                  \n",
      "had_click        1.658*** (0.0168)\n",
      "had_click_lag1  0.1761*** (0.0252)\n",
      "Fixed-Effects:  ------------------\n",
      "user_id                        Yes\n",
      "vendor_id                      Yes\n",
      "week                           Yes\n",
      "_______________ __________________\n",
      "S.E.: Clustered        by: user_id\n",
      "Observations             3,462,867\n",
      "Squared Cor.               0.07374\n",
      "Pseudo R2                  0.24092\n",
      "BIC                      573,493.6\n",
      "---\n",
      "Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "✅ Distributed lag logit model estimated successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import polars as pl\n",
    "\n",
    "# --- 1. Set up rpy2 Environment (Unchanged) ---\n",
    "def setup_rpy2():\n",
    "    \"\"\"Initializes the rpy2 environment and returns key objects.\"\"\"\n",
    "    try:\n",
    "        import rpy2.robjects as ro\n",
    "        from rpy2.robjects.packages import importr\n",
    "        from rpy2.robjects import pandas2ri\n",
    "        from rpy2.robjects.conversion import localconverter\n",
    "        importr('fixest')\n",
    "        print(\"✅ rpy2 environment and 'fixest' library loaded successfully.\")\n",
    "        return True, ro, pandas2ri, localconverter\n",
    "    except (ImportError, RuntimeError) as e:\n",
    "        print(f\"❌ ERROR: Failed to set up rpy2: {e}\", file=sys.stderr)\n",
    "        return False, None, None, None\n",
    "\n",
    "# --- 2. Load, Sample, Balance, and Prepare Data ---\n",
    "def load_and_prepare_data(filename, sample_fraction=1.0):\n",
    "    \"\"\"\n",
    "    Loads, samples users, balances the panel, and prepares variables for a\n",
    "    distributed lag logit model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"--- Loading unbalanced panel data from '{filename}' ---\")\n",
    "        df_unbalanced = pl.read_parquet(filename)\n",
    "\n",
    "        if sample_fraction < 1.0:\n",
    "            print(f\"--- Sub-sampling {sample_fraction:.0%} of users... ---\")\n",
    "            unique_users = df_unbalanced.get_column(\"user_id\").unique()\n",
    "            sampled_users = unique_users.sample(fraction=sample_fraction, shuffle=True)\n",
    "            df_sampled = df_unbalanced.filter(pl.col(\"user_id\").is_in(sampled_users))\n",
    "            print(f\"✅ Sampled data contains {df_sampled.height:,} rows from {sampled_users.len():,} users.\")\n",
    "        else:\n",
    "            df_sampled = df_unbalanced\n",
    "            print(\"✅ Using full dataset (no sampling).\")\n",
    "\n",
    "        print(\"--- Balancing the panel for the sampled user-vendor pairs ---\")\n",
    "        all_pairs = df_sampled.select(\"user_id\", \"vendor_id\").unique()\n",
    "        all_weeks = df_sampled.select(\"week\").unique()\n",
    "        df_grid = all_pairs.join(all_weeks, how=\"cross\")\n",
    "        df_balanced = df_grid.join(\n",
    "            df_sampled, on=[\"user_id\", \"vendor_id\", \"week\"], how=\"left\"\n",
    "        ).with_columns(\n",
    "            pl.col(\"clicks\").fill_null(0),\n",
    "            pl.col(\"purchases\").fill_null(0)\n",
    "        )\n",
    "        print(f\"✅ Panel balanced. New size: {df_balanced.height:,} rows.\")\n",
    "\n",
    "        print(\"--- Preparing binary and lagged click variables ---\")\n",
    "        df_prepared = df_balanced.select(\n",
    "            \"user_id\", \"vendor_id\", \"week\", \"purchases\", \"clicks\"\n",
    "        ).with_columns(\n",
    "            pl.when(pl.col(\"purchases\") > 0).then(1).otherwise(0).alias(\"did_purchase\"),\n",
    "            pl.when(pl.col(\"clicks\") > 0).then(1).otherwise(0).alias(\"had_click\")\n",
    "        )\n",
    "        \n",
    "        df_sorted = df_prepared.sort(\"user_id\", \"vendor_id\", \"week\")\n",
    "        \n",
    "        # --- MODIFIED: No longer need to create did_purchase_lag1 ---\n",
    "        df_final = df_sorted.with_columns(\n",
    "            pl.col(\"had_click\").shift(1).over([\"user_id\", \"vendor_id\"]).alias(\"had_click_lag1\")\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Lagged variables created successfully.\")\n",
    "        return df_final\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ ERROR: The file '{filename}' was not found.\", file=sys.stderr)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR during data loading or preparation: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "# --- 3. Run the Distributed Lag Fixed-Effects Logit Model ---\n",
    "def run_distributed_lag_feglm_model(df, ro, pandas2ri, localconverter):\n",
    "    \"\"\"\n",
    "    Runs a three-way fixed-effects logit model with concurrent and lagged clicks.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Estimating Distributed Lag Panel Logit Model ---\")\n",
    "    print(\"Model: Pr(Purchase=1) ~ Had_Click + Had_Click_Lag1 | FEs\")\n",
    "    \n",
    "    try:\n",
    "        df_pd = df.to_pandas()\n",
    "        with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "            ro.globalenv['df_for_r'] = df_pd\n",
    "\n",
    "        # --- MODIFIED: Simplified R formula ---\n",
    "        ro.r(\"\"\"\n",
    "        library(fixest)\n",
    "        df_panel <- df_for_r\n",
    "        \n",
    "        # This model estimates the effect of concurrent and lagged clicks,\n",
    "        # without controlling for the lagged purchase event itself.\n",
    "        model_dist_lag <- feglm(\n",
    "            did_purchase ~ had_click + had_click_lag1,\n",
    "            data = df_panel,\n",
    "            family = \"logit\",\n",
    "            fixef = c(\"user_id\", \"vendor_id\", \"week\"),\n",
    "            vcov = ~user_id,\n",
    "            glm.iter = 100\n",
    "        )\n",
    "        \n",
    "        print(etable(model_dist_lag, digits = 4))\n",
    "        \"\"\")\n",
    "        \n",
    "        print(\"\\n✅ Distributed lag logit model estimated successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR running the feglm model in R: {e}\", file=sys.stderr)\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "def main():\n",
    "    \"\"\"Orchestrates the loading, preparation, and modeling process.\"\"\"\n",
    "    FILENAME = 'user_vendor_panel_power_players_2mo.parquet'\n",
    "    SAMPLE_FRACTION = 0.5 # Use 25% for a faster run. Set to 1.0 for full data.\n",
    "    \n",
    "    rpy2_is_ready, ro, pandas2ri, localconverter = setup_rpy2()\n",
    "    if not rpy2_is_ready:\n",
    "        sys.exit(1)\n",
    "\n",
    "    df_analysis = load_and_prepare_data(FILENAME, sample_fraction=SAMPLE_FRACTION)\n",
    "\n",
    "    if df_analysis is not None and not df_analysis.is_empty():\n",
    "        run_distributed_lag_feglm_model(df_analysis, ro, pandas2ri, localconverter)\n",
    "    else:\n",
    "        print(\"Skipping model estimation due to data loading issues.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47979b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
