{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f8167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Snowflake\n",
      "\n",
      "--- Generating User-Vendor-Week Panel for Pilot Week ---\n",
      "   Using data from 2025-07-01 00:00:00 to 2025-07-08 00:00:00 (exclusive)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "import sys\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Your provided Snowflake connection details ---\n",
    "# This connection is for *reading* from INCREMENTALITY.\n",
    "# We no longer need to switch contexts, as we are not creating objects.\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.getenv('SNOWFLAKE_USER'),\n",
    "    password=os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "    account=os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "    warehouse=os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH'),\n",
    "    database='INCREMENTALITY', # Source database for Clicks and Purchases\n",
    "    schema='INCREMENTALITY_RESEARCH' # Schema for Clicks and Purchases\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def run_query(query):\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        # For SELECT queries, fetch results\n",
    "        if cursor.description:\n",
    "            results = cursor.fetchall()\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            return pd.DataFrame(results, columns=columns)\n",
    "        # For DDL/DML, no results to fetch (though we won't be doing DDL now)\n",
    "        return pd.DataFrame()\n",
    "    except snowflake.connector.ProgrammingError as e:\n",
    "        print(f\"\\nERROR executing query:\\n{query}\\nDetails: {e}\")\n",
    "        raise # Re-raise the exception to stop execution on error\n",
    "\n",
    "def show_table(df, title=\"\"):\n",
    "    if title:\n",
    "        print(f\"\\n{title}\")\n",
    "        print(\"=\"*len(title))\n",
    "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
    "\n",
    "print(\"✅ Connected to Snowflake\")\n",
    "\n",
    "# Define the pilot week for consistency\n",
    "PILOT_WEEK_START = '2025-07-01 00:00:00'\n",
    "PILOT_WEEK_END = '2025-07-08 00:00:00' # End is exclusive\n",
    "\n",
    "print(\"\\n--- Generating User-Vendor-Week Panel for Pilot Week ---\")\n",
    "print(f\"   Using data from {PILOT_WEEK_START} to {PILOT_WEEK_END} (exclusive)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration for Full-History Panel ---\n",
    "print(f\"--- Generating Full-History Clicks-Only Vendor Panel ---\")\n",
    "print(\"   Based on the date check, this will process data from roughly 2025-03-14 to 2025-09-07.\")\n",
    "\n",
    "# --- Define the Full-History Vendor-Week Panel Aggregation Query ---\n",
    "# This query processes all available data by removing the WHERE date clauses.\n",
    "vendor_panel_query_full_history = \"\"\"\n",
    "WITH\n",
    "-- Step 1: Aggregate all historical clicks per vendor *per week*.\n",
    "CLICKS_WEEKLY AS (\n",
    "    SELECT\n",
    "        VENDOR_ID,\n",
    "        DATE_TRUNC('WEEK', OCCURRED_AT) AS week,\n",
    "        COUNT(DISTINCT INTERACTION_ID) AS click_count\n",
    "    FROM CLICKS\n",
    "    GROUP BY VENDOR_ID, week\n",
    "),\n",
    "\n",
    "-- Step 2: Create a CLICK-BASED map from all historical data.\n",
    "PRODUCT_VENDOR_MAP_CLICKS AS (\n",
    "    SELECT DISTINCT PRODUCT_ID, VENDOR_ID\n",
    "    FROM CLICKS\n",
    "    WHERE VENDOR_ID IS NOT NULL AND PRODUCT_ID IS NOT NULL\n",
    "),\n",
    "\n",
    "-- Step 3: Aggregate all historical attributed purchases and revenue per vendor *per week*.\n",
    "PURCHASES_WEEKLY AS (\n",
    "    SELECT\n",
    "        pvm.VENDOR_ID,\n",
    "        DATE_TRUNC('WEEK', p.PURCHASED_AT) AS week,\n",
    "        COUNT(DISTINCT p.PURCHASE_ID) AS purchase_count,\n",
    "        COALESCE(SUM(p.QUANTITY * p.UNIT_PRICE), 0) AS total_revenue_cents\n",
    "    FROM PURCHASES AS p\n",
    "    JOIN PRODUCT_VENDOR_MAP_CLICKS AS pvm ON p.PRODUCT_ID = pvm.PRODUCT_ID\n",
    "    GROUP BY pvm.VENDOR_ID, week\n",
    ")\n",
    "\n",
    "-- Final Step: Join all weekly aggregates into the final panel.\n",
    "SELECT\n",
    "    c.week,\n",
    "    c.vendor_id,\n",
    "    c.click_count AS clicks,\n",
    "    COALESCE(p.purchase_count, 0) AS purchases,\n",
    "    (COALESCE(p.total_revenue_cents, 0) / 100)::DECIMAL(18, 2) AS revenue_dollars\n",
    "    \n",
    "FROM CLICKS_WEEKLY AS c\n",
    "LEFT JOIN PURCHASES_WEEKLY AS p ON c.vendor_id = p.vendor_id AND c.week = p.week\n",
    "ORDER BY c.vendor_id, c.week;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Execute the query to build the full panel\n",
    "    vendor_panel_full_df = run_query(vendor_panel_query_full_history)\n",
    "    print(f\"\\n✅ Successfully generated full-history panel with {len(vendor_panel_full_df):,} rows.\")\n",
    "\n",
    "    # Process and save the DataFrame\n",
    "    vendor_panel_full_df.columns = [col.lower() for col in vendor_panel_full_df.columns]\n",
    "    \n",
    "    # Save to a new Parquet file\n",
    "    output_filename = \"vendor_panel_full_history_clicks_only.parquet\"\n",
    "    vendor_panel_full_df.to_parquet(output_filename, index=False, engine='pyarrow')\n",
    "    \n",
    "    print(f\"\\n✅ Data successfully processed and saved to '{output_filename}'\")\n",
    "    show_table(vendor_panel_full_df.head(10), f\"Data Sample from '{output_filename}'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during panel generation: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
