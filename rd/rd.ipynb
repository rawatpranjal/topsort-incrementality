{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02f21df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Snowflake\n",
      "\n",
      "--- Generating User-Vendor-Week Panel for Pilot Week ---\n",
      "   Using data from 2025-07-01 00:00:00 to 2025-07-08 00:00:00 (exclusive)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from dotenv import load_dotenv\n",
    "import snowflake.connector\n",
    "import sys\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Your provided Snowflake connection details ---\n",
    "# This connection is for *reading* from INCREMENTALITY.\n",
    "# We no longer need to switch contexts, as we are not creating objects.\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.getenv('SNOWFLAKE_USER'),\n",
    "    password=os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "    account=os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "    warehouse=os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH'),\n",
    "    database='INCREMENTALITY', # Source database for Clicks and Purchases\n",
    "    schema='INCREMENTALITY_RESEARCH' # Schema for Clicks and Purchases\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def run_query(query):\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        # For SELECT queries, fetch results\n",
    "        if cursor.description:\n",
    "            results = cursor.fetchall()\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            return pd.DataFrame(results, columns=columns)\n",
    "        # For DDL/DML, no results to fetch (though we won't be doing DDL now)\n",
    "        return pd.DataFrame()\n",
    "    except snowflake.connector.ProgrammingError as e:\n",
    "        print(f\"\\nERROR executing query:\\n{query}\\nDetails: {e}\")\n",
    "        raise # Re-raise the exception to stop execution on error\n",
    "\n",
    "def show_table(df, title=\"\"):\n",
    "    if title:\n",
    "        print(f\"\\n{title}\")\n",
    "        print(\"=\"*len(title))\n",
    "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
    "\n",
    "print(\"✅ Connected to Snowflake\")\n",
    "\n",
    "# Define the pilot week for consistency\n",
    "PILOT_WEEK_START = '2025-07-01 00:00:00'\n",
    "PILOT_WEEK_END = '2025-07-08 00:00:00' # End is exclusive\n",
    "\n",
    "print(\"\\n--- Generating User-Vendor-Week Panel for Pilot Week ---\")\n",
    "print(f\"   Using data from {PILOT_WEEK_START} to {PILOT_WEEK_END} (exclusive)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd4e46b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running 2-Minute Spike Test ---\n",
      "Window: 2025-07-06 16:00:00 to 2025-07-06 16:02:00\n",
      "Executing queries...\n",
      "\n",
      "Diagnostic complete. Report saved to 'spike_test_report_20250706.txt'.\n",
      "Final Diagnostic Spike Test Report\n",
      "========================================\n",
      "Time Window: 2025-07-06 16:00:00 to 2025-07-06 16:02:00\n",
      "----------------------------------------\n",
      "\n",
      "1. Total Rank 1 Winning Bids in Window: 13,653\n",
      "2. Total Impressions Logged in Window:   65,306\n",
      "3. Verifiable Matches (Joins) Found:    0\n",
      "\n",
      "CONCLUSION:\n",
      "TOTAL FAILURE CONFIRMED.\n",
      "Both winning bids and impressions were logged in this window, but ZERO records can be joined.\n",
      "The data link is fundamentally broken or the join keys are incorrect. Escalate to Engineering.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- Configuration ---\n",
    "TARGET_DATETIME_START = '2025-07-06 16:00:00'\n",
    "TARGET_DATETIME_END = (datetime.strptime(TARGET_DATETIME_START, '%Y-%m-%d %H:%M:%S') + timedelta(minutes=2)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "IMPRESSION_WINDOW_END = (datetime.strptime(TARGET_DATETIME_END, '%Y-%m-%d %H:%M:%S') + timedelta(seconds=30)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "DB_SCHEMA = \"INCREMENTALITY.INCREMENTALITY_RESEARCH\"\n",
    "\n",
    "# --- Define Helper for Clean Reports ---\n",
    "def format_df_to_text(df, title):\n",
    "    \"\"\"Formats a pandas DataFrame into a reStructuredText simple table string.\"\"\"\n",
    "    df_str = df.astype(str)\n",
    "    header = df_str.columns.tolist()\n",
    "    data = df_str.values.tolist()\n",
    "    col_widths = [max(len(x) for x in col) for col in zip(*([header] + data))]\n",
    "    \n",
    "    separator = '+' + '+'.join('-' * (w + 2) for w in col_widths) + '+'\n",
    "    header_line = '|' + '|'.join(f' {h:<{w}} ' for h, w in zip(header, col_widths)) + '|'\n",
    "    \n",
    "    data_lines = []\n",
    "    for row in data:\n",
    "        data_lines.append('|' + '|'.join(f' {item:<{w}} ' for item, w in zip(row, col_widths)) + '|')\n",
    "    \n",
    "    report_lines = [\n",
    "        \"=\" * (len(title) + 4),\n",
    "        f\"  {title}  \",\n",
    "        \"=\" * (len(title) + 4),\n",
    "        separator,\n",
    "        header_line,\n",
    "        separator.replace('-', '='),\n",
    "    ]\n",
    "    report_lines.extend(data_lines)\n",
    "    report_lines.append(separator)\n",
    "    \n",
    "    return \"\\n\".join(report_lines)\n",
    "\n",
    "# --- Spike Test Logic ---\n",
    "try:\n",
    "    print(f\"--- Running 2-Minute Spike Test ---\")\n",
    "    print(f\"Window: {TARGET_DATETIME_START} to {TARGET_DATETIME_END}\")\n",
    "\n",
    "    # Query 1: Count Rank 1 Winners in the window\n",
    "    query1 = f\"\"\"\n",
    "    SELECT COUNT(*) AS count_rank_1_wins\n",
    "    FROM {DB_SCHEMA}.AUCTIONS_RESULTS\n",
    "    WHERE CREATED_AT BETWEEN '{TARGET_DATETIME_START}' AND '{TARGET_DATETIME_END}'\n",
    "      AND IS_WINNER = TRUE\n",
    "      AND RANKING = 1;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query 2: Count Impressions in the window\n",
    "    query2 = f\"\"\"\n",
    "    SELECT COUNT(*) AS count_impressions\n",
    "    FROM {DB_SCHEMA}.IMPRESSIONS\n",
    "    WHERE OCCURRED_AT BETWEEN '{TARGET_DATETIME_START}' AND '{IMPRESSION_WINDOW_END}';\n",
    "    \"\"\"\n",
    "    \n",
    "    # Query 3: The Definitive Join Test with CORRECTED column name\n",
    "    query3 = f\"\"\"\n",
    "    WITH WindowWinningBids AS (\n",
    "        SELECT\n",
    "            ar.AUCTION_ID,\n",
    "            -- CORRECTED: Use OPAQUE_USER_ID from AUCTIONS_USERS and alias it\n",
    "            au.OPAQUE_USER_ID AS USER_ID,\n",
    "            ar.VENDOR_ID,\n",
    "            ar.PRODUCT_ID\n",
    "        FROM {DB_SCHEMA}.AUCTIONS_RESULTS ar\n",
    "        JOIN {DB_SCHEMA}.AUCTIONS_USERS au ON ar.AUCTION_ID = au.AUCTION_ID\n",
    "        WHERE ar.CREATED_AT BETWEEN '{TARGET_DATETIME_START}' AND '{TARGET_DATETIME_END}'\n",
    "          AND ar.IS_WINNER = TRUE\n",
    "          AND ar.RANKING = 1\n",
    "    ),\n",
    "    WindowImpressions AS (\n",
    "        SELECT\n",
    "            TRY_HEX_DECODE_BINARY(AUCTION_ID) AS AUCTION_ID_BINARY,\n",
    "            USER_ID,\n",
    "            TRY_HEX_DECODE_BINARY(VENDOR_ID) AS VENDOR_ID_BINARY,\n",
    "            PRODUCT_ID\n",
    "        FROM {DB_SCHEMA}.IMPRESSIONS\n",
    "        WHERE OCCURRED_AT BETWEEN '{TARGET_DATETIME_START}' AND '{IMPRESSION_WINDOW_END}'\n",
    "    )\n",
    "    SELECT\n",
    "        COUNT(*) AS successful_joins\n",
    "    FROM WindowWinningBids b\n",
    "    INNER JOIN WindowImpressions i\n",
    "        ON b.AUCTION_ID = i.AUCTION_ID_BINARY\n",
    "        AND b.USER_ID = i.USER_ID\n",
    "        AND b.VENDOR_ID = i.VENDOR_ID_BINARY\n",
    "        AND b.PRODUCT_ID = i.PRODUCT_ID;\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Execute Queries ---\n",
    "    print(\"Executing queries...\")\n",
    "    rank_1_wins = run_query(query1).iloc[0, 0]\n",
    "    impressions_count = run_query(query2).iloc[0, 0]\n",
    "    join_count = run_query(query3).iloc[0, 0]\n",
    "    \n",
    "    # --- Generate Final Report ---\n",
    "    report_filename = f\"spike_test_report_{TARGET_DATE.replace('-', '')}.txt\"\n",
    "    with open(report_filename, \"w\") as f:\n",
    "        f.write(f\"Final Diagnostic Spike Test Report\\n\")\n",
    "        f.write(\"=\"*40 + \"\\n\")\n",
    "        f.write(f\"Time Window: {TARGET_DATETIME_START} to {TARGET_DATETIME_END}\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"1. Total Rank 1 Winning Bids in Window: {rank_1_wins:,}\\n\")\n",
    "        f.write(f\"2. Total Impressions Logged in Window:   {impressions_count:,}\\n\")\n",
    "        f.write(f\"3. Verifiable Matches (Joins) Found:    {join_count:,}\\n\\n\")\n",
    "        \n",
    "        f.write(\"CONCLUSION:\\n\")\n",
    "        \n",
    "        if join_count > 0:\n",
    "            success_rate = (join_count / rank_1_wins) if rank_1_wins > 0 else 0\n",
    "            f.write(f\"SUCCESS. A data link exists. The match rate is {success_rate:.2%}.\\n\")\n",
    "            f.write(\"The issue is not a total system failure but likely a data quality problem or a partial logging issue that causes the broader queries to fail.\\n\")\n",
    "            f.write(\"Next step is to debug the keys on the non-matching records.\\n\")\n",
    "        else:\n",
    "            if rank_1_wins > 0 and impressions_count > 0:\n",
    "                f.write(\"TOTAL FAILURE CONFIRMED.\\n\")\n",
    "                f.write(\"Both winning bids and impressions were logged in this window, but ZERO records can be joined.\\n\")\n",
    "                f.write(\"The data link is fundamentally broken or the join keys are incorrect. Escalate to Engineering.\\n\")\n",
    "            elif rank_1_wins == 0:\n",
    "                f.write(\"INCONCLUSIVE (No Wins).\\n\")\n",
    "                f.write(\"There were no winning bids in this time window to test. Please select a different time.\\n\")\n",
    "            else: # impressions_count == 0\n",
    "                f.write(\"FAILURE (No Impressions).\\n\")\n",
    "                f.write(\"There were winning bids, but zero impressions were logged in this window. The impression logging system appears to be down. Escalate to Engineering.\\n\")\n",
    "\n",
    "    print(f\"\\nDiagnostic complete. Report saved to '{report_filename}'.\")\n",
    "    with open(report_filename, 'r') as f:\n",
    "        print(f.read())\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nERROR: The 'run_query' function is not defined.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during the spike test: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59522c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Final Look-Ahead Diagnostic (30-Minute Window) ---\n",
      "Auction Window: 2025-07-06 16:00:00 to 2025-07-06 16:02:00\n",
      "Executing look-ahead query...\n",
      "Diagnostic complete. Report saved to 'lookahead_diagnostic_report_20250706.txt'.\n",
      "Final Look-Ahead Diagnostic Report: 2025-07-06\n",
      "============================================================\n",
      "\n",
      "This report tests if a winning bid is followed by an impression for the same (USER, VENDOR, PRODUCT) within 30 minutes, ignoring AUCTION_ID.\n",
      "\n",
      "Total Winning Bids in 2-Min Window: 370,505\n",
      "Wins with a Subsequent Impression (within 30 mins): 0\n",
      "Successful Look-Ahead Match Rate: 0.00%\n",
      "\n",
      "------------------------------------------------------------\n",
      "CONCLUSION:\n",
      "ULTIMATE FAILURE CONFIRMED.\n",
      "Even with a generous 30-minute look-ahead window, no meaningful link can be established between a winning bid and a subsequent impression.\n",
      "We have now exhausted all plausible data linkage hypotheses. The data instrumentation is fundamentally and completely broken.\n",
      "Recommendation: Escalate to Engineering. All incrementality analysis is BLOCKED.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- Configuration ---\n",
    "TARGET_DATETIME_START = '2025-07-06 16:00:00'\n",
    "TARGET_DATETIME_END = (datetime.strptime(TARGET_DATETIME_START, '%Y-%m-%d %H:%M:%S') + timedelta(minutes=2)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "# Define a generous 30-minute look-ahead window for impressions\n",
    "LOOKAHEAD_WINDOW_END = (datetime.strptime(TARGET_DATETIME_END, '%Y-%m-%d %H:%M:%S') + timedelta(minutes=30)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "DB_SCHEMA = \"INCREMENTALITY.INCREMENTALITY_RESEARCH\"\n",
    "\n",
    "# --- Final Diagnostic Logic ---\n",
    "try:\n",
    "    print(f\"--- Running Final Look-Ahead Diagnostic (30-Minute Window) ---\")\n",
    "    print(f\"Auction Window: {TARGET_DATETIME_START} to {TARGET_DATETIME_END}\")\n",
    "\n",
    "    # This query tests for a time-based link, ignoring the AUCTION_ID in the join.\n",
    "    lookahead_query = f\"\"\"\n",
    "    WITH WindowWinningBids AS (\n",
    "        -- Step 1: Get all winning bids in the window, with their exact win time and user.\n",
    "        SELECT\n",
    "            au.OPAQUE_USER_ID AS USER_ID,\n",
    "            ar.VENDOR_ID,\n",
    "            ar.PRODUCT_ID,\n",
    "            ar.CREATED_AT AS WIN_TIME\n",
    "        FROM {DB_SCHEMA}.AUCTIONS_RESULTS ar\n",
    "        JOIN {DB_SCHEMA}.AUCTIONS_USERS au ON ar.AUCTION_ID = au.AUCTION_ID\n",
    "        WHERE ar.CREATED_AT BETWEEN '{TARGET_DATETIME_START}' AND '{TARGET_DATETIME_END}'\n",
    "          AND ar.IS_WINNER = TRUE\n",
    "    ),\n",
    "    ImpressionsInLookahead AS (\n",
    "        -- Step 2: Get all impressions in the wider look-ahead window.\n",
    "        SELECT\n",
    "            USER_ID,\n",
    "            TRY_HEX_DECODE_BINARY(VENDOR_ID) AS VENDOR_ID_BINARY,\n",
    "            PRODUCT_ID,\n",
    "            OCCURRED_AT AS IMPRESSION_TIME\n",
    "        FROM {DB_SCHEMA}.IMPRESSIONS\n",
    "        -- Filter impressions to the relevant time window for performance.\n",
    "        WHERE OCCURRED_AT BETWEEN '{TARGET_DATETIME_START}' AND '{LOOKAHEAD_WINDOW_END}'\n",
    "    )\n",
    "    -- Step 3: Count total wins and find matches where an impression occurred AFTER the win for the same tuple.\n",
    "    SELECT\n",
    "        COUNT(b.WIN_TIME) AS total_wins_in_window,\n",
    "        COUNT(i.IMPRESSION_TIME) AS wins_with_lookahead_impression\n",
    "    FROM WindowWinningBids b\n",
    "    LEFT JOIN ImpressionsInLookahead i\n",
    "        -- The join key is now the stable (USER, VENDOR, PRODUCT) tuple.\n",
    "        ON b.USER_ID = i.USER_ID\n",
    "        AND b.VENDOR_ID = i.VENDOR_ID_BINARY\n",
    "        AND b.PRODUCT_ID = i.PRODUCT_ID\n",
    "        -- The critical look-ahead condition:\n",
    "        AND i.IMPRESSION_TIME >= b.WIN_TIME\n",
    "        AND DATEDIFF('minute', b.WIN_TIME, i.IMPRESSION_TIME) <= 30;\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Execute the query ---\n",
    "    print(\"Executing look-ahead query...\")\n",
    "    result_df = run_query(lookahead_query)\n",
    "    result_df.columns = result_df.columns.str.lower()\n",
    "    r = result_df.iloc[0].to_dict()\n",
    "\n",
    "    total_wins = r.get('total_wins_in_window', 0) or 0\n",
    "    matched_wins = r.get('wins_with_lookahead_impression', 0) or 0\n",
    "    match_rate = (matched_wins / total_wins) if total_wins > 0 else 0\n",
    "\n",
    "    # --- Generate Final Report ---\n",
    "    report_filename = f\"lookahead_diagnostic_report_{TARGET_DATE.replace('-', '')}.txt\"\n",
    "    with open(report_filename, \"w\") as f:\n",
    "        f.write(f\"Final Look-Ahead Diagnostic Report: {TARGET_DATE}\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(\"This report tests if a winning bid is followed by an impression for the same (USER, VENDOR, PRODUCT) within 30 minutes, ignoring AUCTION_ID.\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Total Winning Bids in 2-Min Window: {total_wins:,}\\n\")\n",
    "        f.write(f\"Wins with a Subsequent Impression (within 30 mins): {matched_wins:,}\\n\")\n",
    "        f.write(f\"Successful Look-Ahead Match Rate: {match_rate:.2%}\\n\\n\")\n",
    "        \n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        f.write(\"CONCLUSION:\\n\")\n",
    "        \n",
    "        if match_rate > 0.01: # Use a small threshold like 1% to declare success\n",
    "            f.write(\"POTENTIAL SUCCESS. A time-based data link exists.\\n\")\n",
    "            f.write(\"The AUCTION_ID key is confirmed to be unreliable for joining wins to impressions.\\n\")\n",
    "            f.write(\"The correct method is to attribute impressions to wins based on the (USER, VENDOR, PRODUCT) tuple within a time window.\\n\")\n",
    "            f.write(\"Next Step: Re-architect the main EDA using this look-ahead logic to find the true visibility cliff.\\n\")\n",
    "        else:\n",
    "            f.write(\"ULTIMATE FAILURE CONFIRMED.\\n\")\n",
    "            f.write(\"Even with a generous 30-minute look-ahead window, no meaningful link can be established between a winning bid and a subsequent impression.\\n\")\n",
    "            f.write(\"We have now exhausted all plausible data linkage hypotheses. The data instrumentation is fundamentally and completely broken.\\n\")\n",
    "            f.write(\"Recommendation: Escalate to Engineering. All incrementality analysis is BLOCKED.\\n\")\n",
    "\n",
    "    print(f\"Diagnostic complete. Report saved to '{report_filename}'.\")\n",
    "    with open(report_filename, 'r') as f:\n",
    "        print(f.read())\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nERROR: The 'run_query' function is not defined.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during the look-ahead diagnostic: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc7fa18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Final Look-Ahead Diagnostic (30-Minute Window) ---\n",
      "Auction Window: 2025-07-06 16:00:00 to 2025-07-06 16:02:00\n",
      "Executing look-ahead query...\n",
      "Diagnostic complete. Report saved to 'lookahead_diagnostic_report_20250706.txt'.\n",
      "Final Look-Ahead Diagnostic Report: 2025-07-06\n",
      "============================================================\n",
      "\n",
      "This report tests if a winning bid is followed by an impression for the same (USER, VENDOR, PRODUCT) within 30 minutes, ignoring AUCTION_ID.\n",
      "\n",
      "Total Winning Bids in 2-Min Window: 370,505\n",
      "Wins with a Subsequent Impression (within 30 mins): 0\n",
      "Successful Look-Ahead Match Rate: 0.00%\n",
      "\n",
      "------------------------------------------------------------\n",
      "CONCLUSION:\n",
      "ULTIMATE FAILURE CONFIRMED.\n",
      "Even with a generous 30-minute look-ahead window, no meaningful link can be established between a winning bid and a subsequent impression.\n",
      "We have now exhausted all plausible data linkage hypotheses. The data instrumentation is fundamentally and completely broken.\n",
      "Recommendation: Escalate to Engineering. All incrementality analysis is BLOCKED.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- Configuration ---\n",
    "TARGET_DATETIME_START = '2025-07-06 16:00:00'\n",
    "TARGET_DATETIME_END = (datetime.strptime(TARGET_DATETIME_START, '%Y-%m-%d %H:%M:%S') + timedelta(minutes=2)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "# Define a generous 30-minute look-ahead window for impressions\n",
    "LOOKAHEAD_WINDOW_END = (datetime.strptime(TARGET_DATETIME_END, '%Y-%m-%d %H:%M:%S') + timedelta(minutes=30)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "DB_SCHEMA = \"INCREMENTALITY.INCREMENTALITY_RESEARCH\"\n",
    "\n",
    "# --- Final Diagnostic Logic ---\n",
    "try:\n",
    "    print(f\"--- Running Final Look-Ahead Diagnostic (30-Minute Window) ---\")\n",
    "    print(f\"Auction Window: {TARGET_DATETIME_START} to {TARGET_DATETIME_END}\")\n",
    "\n",
    "    # This query tests for a time-based link, ignoring the AUCTION_ID in the join.\n",
    "    lookahead_query = f\"\"\"\n",
    "    WITH WindowWinningBids AS (\n",
    "        -- Step 1: Get all winning bids in the window, with their exact win time and user.\n",
    "        SELECT\n",
    "            au.OPAQUE_USER_ID AS USER_ID,\n",
    "            ar.VENDOR_ID,\n",
    "            ar.PRODUCT_ID,\n",
    "            ar.CREATED_AT AS WIN_TIME\n",
    "        FROM {DB_SCHEMA}.AUCTIONS_RESULTS ar\n",
    "        JOIN {DB_SCHEMA}.AUCTIONS_USERS au ON ar.AUCTION_ID = au.AUCTION_ID\n",
    "        WHERE ar.CREATED_AT BETWEEN '{TARGET_DATETIME_START}' AND '{TARGET_DATETIME_END}'\n",
    "          AND ar.IS_WINNER = TRUE\n",
    "    ),\n",
    "    ImpressionsInLookahead AS (\n",
    "        -- Step 2: Get all impressions in the wider look-ahead window.\n",
    "        SELECT\n",
    "            USER_ID,\n",
    "            TRY_HEX_DECODE_BINARY(VENDOR_ID) AS VENDOR_ID_BINARY,\n",
    "            PRODUCT_ID,\n",
    "            OCCURRED_AT AS IMPRESSION_TIME\n",
    "        FROM {DB_SCHEMA}.IMPRESSIONS\n",
    "        -- Filter impressions to the relevant time window for performance.\n",
    "        WHERE OCCURRED_AT BETWEEN '{TARGET_DATETIME_START}' AND '{LOOKAHEAD_WINDOW_END}'\n",
    "    )\n",
    "    -- Step 3: Count total wins and find matches where an impression occurred AFTER the win for the same tuple.\n",
    "    SELECT\n",
    "        COUNT(b.WIN_TIME) AS total_wins_in_window,\n",
    "        COUNT(i.IMPRESSION_TIME) AS wins_with_lookahead_impression\n",
    "    FROM WindowWinningBids b\n",
    "    LEFT JOIN ImpressionsInLookahead i\n",
    "        -- The join key is now the stable (USER, VENDOR, PRODUCT) tuple.\n",
    "        ON b.USER_ID = i.USER_ID\n",
    "        AND b.VENDOR_ID = i.VENDOR_ID_BINARY\n",
    "        AND b.PRODUCT_ID = i.PRODUCT_ID\n",
    "        -- The critical look-ahead condition:\n",
    "        AND i.IMPRESSION_TIME >= b.WIN_TIME\n",
    "        AND DATEDIFF('minute', b.WIN_TIME, i.IMPRESSION_TIME) <= 30;\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Execute the query ---\n",
    "    print(\"Executing look-ahead query...\")\n",
    "    result_df = run_query(lookahead_query)\n",
    "    result_df.columns = result_df.columns.str.lower()\n",
    "    r = result_df.iloc[0].to_dict()\n",
    "\n",
    "    total_wins = r.get('total_wins_in_window', 0) or 0\n",
    "    matched_wins = r.get('wins_with_lookahead_impression', 0) or 0\n",
    "    match_rate = (matched_wins / total_wins) if total_wins > 0 else 0\n",
    "\n",
    "    # --- Generate Final Report ---\n",
    "    report_filename = f\"lookahead_diagnostic_report_{TARGET_DATE.replace('-', '')}.txt\"\n",
    "    with open(report_filename, \"w\") as f:\n",
    "        f.write(f\"Final Look-Ahead Diagnostic Report: {TARGET_DATE}\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(\"This report tests if a winning bid is followed by an impression for the same (USER, VENDOR, PRODUCT) within 30 minutes, ignoring AUCTION_ID.\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Total Winning Bids in 2-Min Window: {total_wins:,}\\n\")\n",
    "        f.write(f\"Wins with a Subsequent Impression (within 30 mins): {matched_wins:,}\\n\")\n",
    "        f.write(f\"Successful Look-Ahead Match Rate: {match_rate:.2%}\\n\\n\")\n",
    "        \n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        f.write(\"CONCLUSION:\\n\")\n",
    "        \n",
    "        if match_rate > 0.01: # Use a small threshold like 1% to declare success\n",
    "            f.write(\"POTENTIAL SUCCESS. A time-based data link exists.\\n\")\n",
    "            f.write(\"The AUCTION_ID key is confirmed to be unreliable for joining wins to impressions.\\n\")\n",
    "            f.write(\"The correct method is to attribute impressions to wins based on the (USER, VENDOR, PRODUCT) tuple within a time window.\\n\")\n",
    "            f.write(\"Next Step: Re-architect the main EDA using this look-ahead logic to find the true visibility cliff.\\n\")\n",
    "        else:\n",
    "            f.write(\"ULTIMATE FAILURE CONFIRMED.\\n\")\n",
    "            f.write(\"Even with a generous 30-minute look-ahead window, no meaningful link can be established between a winning bid and a subsequent impression.\\n\")\n",
    "            f.write(\"We have now exhausted all plausible data linkage hypotheses. The data instrumentation is fundamentally and completely broken.\\n\")\n",
    "            f.write(\"Recommendation: Escalate to Engineering. All incrementality analysis is BLOCKED.\\n\")\n",
    "\n",
    "    print(f\"Diagnostic complete. Report saved to '{report_filename}'.\")\n",
    "    with open(report_filename, 'r') as f:\n",
    "        print(f.read())\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nERROR: The 'run_query' function is not defined.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during the look-ahead diagnostic: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f5de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
